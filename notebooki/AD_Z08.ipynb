{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a615d5",
   "metadata": {},
   "source": [
    "# Laboratorium nr 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef882e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fbb856",
   "metadata": {},
   "source": [
    "## Skalowanie danych\n",
    "Proszę pamiętać, aby zawsze estymować parametry skalowania (średnia i wariancja) na zbiorze treningowym, a nie na całym zbiorze danych. W przeciwym razie, zbierając statystyki z całego zbioru danych, \"przenosimy\" część informacji ze zbioru testowego/walidacyjnego do treningowego, co jest błędem metodologicznym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de748229",
   "metadata": {},
   "source": [
    "### Zadanie nr 1 (1 punkt)\n",
    "Załaduj dane _breast_cancer_, a następnie naucz model SVC na danych (tylko zmienne niezależne!) zestandaryzowanych i niezestandaryzowanych. Użyj w tym celu StandardScalera. Czy jest jakaś różnica w predykcji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad202086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# get the data\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# split it into training and test sets\n",
    "X_train, X_test = train_test_split(X, random_state=5, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf027b2e",
   "metadata": {},
   "source": [
    "## Stratified K fold\n",
    "Wyobraź sobie, że masz torbę pełną kolorowych kulek: 90 czerwonych kulek i 10 niebieskich. Jeśli podzielisz kulki losowo na 5 grup, może się zdarzyć, że w niektórych grupach w ogóle nie będzie niebieskich kulek! Ale jeśli podzielisz kulki uważnie, tak aby w każdej grupie było około 90% czerwonych i 10% niebieskich kulek — tak jak w oryginalnej torbie — wtedy proporcje zostaną zachowane. Właśnie to robi *Stratified K-Fold*! Zachowuje oryginalny rozkład klas w każdym foldzie (podziale). To jest szczególnie ważne, gdy dane są niezbalansowane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1335e4",
   "metadata": {},
   "source": [
    "## Metryki\n",
    "Do oceny jakości modelu używamy następujących metryk:\n",
    "1. Accuracy mierzy procent poprawnych predykcji w stosunku do wszystkich predykcji.\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN},\n",
    "$$ gdzie:\n",
    "- TP (True Positive) – poprawnie przewidziane pozytywne przypadki\n",
    "- TN (True Negative) – poprawnie przewidziane negatywne przypadki\n",
    "- FP (False Positive) – błędnie przewidziane pozytywne przypadki\n",
    "- FN (False Negative) – błędnie przewidziane negatywne przypadki\n",
    "2. Precision mierzy, jaki procent przewidywanych jako pozytywne przykładów faktycznie jest pozytywny.\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}.\n",
    "$$\n",
    "3. Recall mierzy, jaki procent rzeczywistych pozytywnych przypadków został poprawnie wykryty przez model.\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}.\n",
    "$$\n",
    "\n",
    "4. F1-score jest średnią harmoniczną precision i recall.\n",
    "$$\n",
    "\\text{F1\\ Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d4daf",
   "metadata": {},
   "source": [
    "### Zadanie nr 2 (5 punktów)\n",
    "Instrukcje:\n",
    "1. Załaduj zbiór danych Iris.\n",
    "2. Sztucznie zaburz balans klas:\n",
    "    - Nie wyrzucaj danych z jednej klasy.\n",
    "    - Z dwóch pozostałych klas zostaw tylko 30% próbek.\n",
    "\n",
    "Użyj dwóch metod:\n",
    "- KFold (zwykły podział).\n",
    "- StratifiedKFold (podział ze stratfikacją).\n",
    "\n",
    "Następnie dla każdej metody:\n",
    "1. Przeprowadź walidację krzyżową (5-fold) z użyciem regresji logistycznej.\n",
    "2. Wydrukuj rozkład klas w każdym foldzie.\n",
    "3. Wydrukuj dla każdego folda:\n",
    "    - Dokładność klasyfikacji (accuracy).\n",
    "    - Precision.\n",
    "    - Recall.\n",
    "    - F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece29337",
   "metadata": {},
   "source": [
    "## Krzywa ROC i AUC\n",
    "\n",
    "**ROC (Receiver Operating Characteristic curve)** to wykres pokazujący zależność pomiędzy:\n",
    "\n",
    "- **True Positive Rate (TPR)** — czyli czułość (recall)\n",
    "- **False Positive Rate (FPR)** — odsetek fałszywych pozytywów\n",
    "\n",
    "dla różnych progów decyzyjnych.\n",
    "\n",
    "---\n",
    "\n",
    "### Wzory:\n",
    "\n",
    "**True Positive Rate (TPR):**\n",
    "\n",
    "$$\n",
    "\\text{TPR} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "**False Positive Rate (FPR):**\n",
    "\n",
    "$$\n",
    "\\text{FPR} = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "Gdzie:\n",
    "- **TP** (True Positive) — prawidłowo przewidziane pozytywne przypadki\n",
    "- **FP** (False Positive) — błędnie przewidziane pozytywne przypadki\n",
    "- **FN** (False Negative) — błędnie przewidziane negatywne przypadki\n",
    "- **TN** (True Negative) — prawidłowo przewidziane negatywne przypadki\n",
    "\n",
    "---\n",
    "\n",
    "## Co to jest AUC?\n",
    "\n",
    "**AUC (Area Under the Curve)** to **pole pod krzywą ROC**.\n",
    "\n",
    "- AUC = 1.0 oznacza idealnego klasyfikatora.\n",
    "- AUC = 0.5 oznacza losowe zgadywanie.\n",
    "- Im wyższe AUC, tym lepsza jakość klasyfikatora.\n",
    "\n",
    "---\n",
    "\n",
    "## Dlaczego używamy ROC i AUC?\n",
    "\n",
    "- Są **niezależne od konkretnego progu** decyzyjnego.\n",
    "- Bardzo przydatne przy **niezbalansowanych danych**, gdy accuracy może wprowadzać w błąd.\n",
    "- Pozwalają ocenić, jak dobrze klasyfikator odróżnia pozytywne i negatywne przykłady.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24fe9c",
   "metadata": {},
   "source": [
    "### Zadanie 3 (4 punkty)\n",
    "1. Załaduj zbiór danych Iris.\n",
    "2. Zrób klasyfikację tylko dla dwóch klas (np. klasa 0 vs. reszta).\n",
    "3. Podziel dane na zbiór treningowy i testowy.\n",
    "4. Zbuduj Pipeline, składający się z obiektów:\n",
    "    - StandardScaler (skalowanie)\n",
    "    - LogisticRegression (regresja logistyczna jako klasyfikator)\n",
    "    - Przy pomocy GridSearchCV znajdź najlepsze parametry dla regresji logistycznej (C, penalty).\n",
    "5. Oceń wyniki na zbiorze testowym.\n",
    "6. Narysuj krzywą ROC i podaj AUC (Area Under Curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do budowy pipeline'u. Żeby zobaczyć, jak go używać, sprawdź dokumentację.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
