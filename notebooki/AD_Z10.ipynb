{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2a5066",
   "metadata": {},
   "source": [
    "# Laboratorium nr 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy niezbędnych paczek\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fd154",
   "metadata": {},
   "source": [
    "# Ensemble i Soft Voting\n",
    "\n",
    "## Czym są metody ensemble?\n",
    "\n",
    "Metody ensemble (ang. ensemble methods) to techniki w uczeniu maszynowym, które łączą przewidywania wielu modeli (tzw. modeli bazowych) w celu uzyskania lepszej dokładności i stabilności predykcji niż pojedynczy model. Ideą jest wykorzystanie różnorodności modeli, aby zredukować błędy wynikające z nadmiernego dopasowania (overfitting), wariancji lub obciążenia (bias).\n",
    "\n",
    "### Główne typy metod ensemble:\n",
    "1. **Bagging** (Bootstrap Aggregating): Modele trenuje się na różnych podzbiorach danych (losowo wybieranych z powtórzeniami), a wyniki są agregowane, np. przez średnią (dla regresji) lub głosowanie większościowe (dla klasyfikacji). Przykład: Random Forest.\n",
    "2. **Boosting**: Modele trenuje się sekwencyjnie, gdzie każdy kolejny model skupia się na poprawianiu błędów poprzednich. Przykład: Gradient Boosting, AdaBoost.\n",
    "3. **Stacking**: Wyniki wielu modeli są łączone za pomocą meta-modelu, który uczy się, jak najlepiej ważyć przewidywania modeli bazowych.\n",
    "4. **Voting**: Przewidywania wielu modeli są łączone przez głosowanie (dla klasyfikacji) lub średnią (dla regresji). Wyróżniamy **hard voting** i **soft voting**.\n",
    "\n",
    "---\n",
    "\n",
    "## Soft Voting - Szczegóły i Matematyka\n",
    "\n",
    "### Czym jest soft voting?\n",
    "\n",
    "Soft voting to technika ensemble dla problemów klasyfikacji, w której przewidywania modeli bazowych są łączone na podstawie **prawdopodobieństw przynależności do klas**. Każdy model bazowy zwraca prawdopodobieństwa dla każdej klasy, a końcowa predykcja jest obliczana jako średnia ważona tych prawdopodobieństw, po czym wybierana jest klasa o najwyższym średnim prawdopodobieństwie.\n",
    "\n",
    "W przeciwieństwie do **hard voting**, gdzie każdy model oddaje jeden \"głos\" na klasę (wynik jest liczony jako większość głosów), soft voting uwzględnia pewność modelu wyrażoną w prawdopodobieństwach, co zazwyczaj prowadzi do lepszych wyników.\n",
    "\n",
    "### Formalny opis matematyczny\n",
    "\n",
    "Załóżmy, że mamy:\n",
    "- $ M $ modeli bazowych (np. drzewa decyzyjne, SVM, sieci neuronowe).\n",
    "- $ K $ klas, które przewidujemy (np. $ K = 3 $ dla klas: \"kot\", \"pies\", \"ptak\").\n",
    "- Dla każdego modelu $ m $ (gdzie $ m = 1, 2, \\dots, M $) i dla każdej próbki $ x $, model zwraca wektor prawdopodobieństw przynależności do klas:\n",
    "  $$\n",
    "  P_m(x) = [p_{m,1}(x), p_{m,2}(x), \\dots, p_{m,K}(x)],\n",
    "  $$\n",
    "  gdzie $ p_{m,k}(x) $ to prawdopodobieństwo, że próbka $ x $ należy do klasy $ k $ według modelu $ m $, oraz $ \\sum_{k=1}^K p_{m,k}(x) = 1 $.\n",
    "\n",
    "#### Krok 1: Obliczenie średnich prawdopodobieństw\n",
    "Dla każdej klasy $ k $, obliczamy średnie prawdopodobieństwo na podstawie wszystkich modeli:\n",
    "$$\n",
    "\\bar{p}_k(x) = \\frac{1}{M} \\sum_{m=1}^M p_{m,k}(x).\n",
    "$$\n",
    "Jeśli modele mają różne wagi $ w_m $ (gdzie $ \\sum_{m=1}^M w_m = 1 $), to:\n",
    "$$\n",
    "\\bar{p}_k(x) = \\sum_{m=1}^M w_m \\cdot p_{m,k}(x).\n",
    "$$\n",
    "\n",
    "#### Krok 2: Wybór klasy\n",
    "Końcowa predykcja to klasa $ k^* $, która ma najwyższe średnie prawdopodobieństwo:\n",
    "$$\n",
    "k^* = \\arg\\max_{k \\in \\{1, 2, \\dots, K\\}} \\bar{p}_k(x).\n",
    "$$\n",
    "\n",
    "### Przykład\n",
    "Załóżmy, że mamy 3 modele ($ M = 3 $) i 2 klasy ($ K = 2 $, np. \"pozytywna\" i \"negatywna\"). Dla próbki $ x $, modele zwracają następujące prawdopodobieństwa:\n",
    "\n",
    "- Model 1: $ P_1(x) = [0.9, 0.1] $ (90% na klasę pozytywną, 10% na negatywną).\n",
    "- Model 2: $ P_2(x) = [0.7, 0.3] $.\n",
    "- Model 3: $ P_3(x) = [0.6, 0.4] $.\n",
    "\n",
    "Obliczamy średnie prawdopodobieństwa dla każdej klasy:\n",
    "$$\n",
    "\\bar{p}_1(x) = \\frac{0.9 + 0.7 + 0.6}{3} = 0.733,\n",
    "$$\n",
    "$$\n",
    "\\bar{p}_2(x) = \\frac{0.1 + 0.3 + 0.4}{3} = 0.267.\n",
    "$$\n",
    "Klasa o najwyższym prawdopodobieństwie to klasa 1 (pozytywna), więc $ k^* = 1 $.\n",
    "\n",
    "---\n",
    "\n",
    "## Zalety i wady soft voting\n",
    "\n",
    "### Zalety:\n",
    "- Uwzględnia pewność modeli, co prowadzi do bardziej wyważonych decyzji.\n",
    "- Często daje lepsze wyniki niż hard voting, szczególnie gdy modele są dobrze skalibrowane.\n",
    "- Elastyczność w stosowaniu wag dla różnych modeli.\n",
    "\n",
    "### Wady:\n",
    "- Wymaga, aby modele zwracały dobrze skalibrowane prawdopodobieństwa.\n",
    "- Większa złożoność obliczeniowa w porównaniu do hard voting.\n",
    "- Może być mniej skuteczne, jeśli modele są bardzo różne pod względem jakości predykcji.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4ad00",
   "metadata": {},
   "source": [
    "### Zadanie nr 1 (5 pkt)\n",
    "Zaimplementuj klasyfikator ensemble z soft voting w Pythonie. Porównaj wyniki z wbudowanym modelem `VotingClassifier`.\n",
    "\n",
    "1. Wygeneruj syntetyczny zbiór danych binarnej klasyfikacji (np. za pomocą `make_classification` z scikit-learn).\n",
    "2. Zbuduj trzy różne modele bazowe (np. Logistic Regression, Decision Tree, SVM).\n",
    "3. Zaimplementuj soft voting ręcznie, obliczając średnie prawdopodobieństwa dla każdej klasy.\n",
    "4. Porównaj wyniki swojej implementacji z modelem `VotingClassifier` z scikit-learn.\n",
    "5. Oceń dokładność (accuracy) obu podejść na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52bb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3423f331",
   "metadata": {},
   "source": [
    "# Lasy Losowe\n",
    "\n",
    "## Czym są lasy losowe?\n",
    "\n",
    "Lasy losowe (ang. Random Forests) to metoda ensemble oparta na technice **bagging** (Bootstrap Aggregating), która łączy wiele drzew decyzyjnych w celu poprawy dokładności i stabilności predykcji. Została zaproponowana przez Leo Breimana w 2001 roku i jest szeroko stosowana zarówno w zadaniach klasyfikacji, jak i regresji.\n",
    "\n",
    "### Kluczowe cechy lasów losowych:\n",
    "1. **Wiele drzew decyzyjnych**: Las losowy składa się z $ T $ drzew decyzyjnych, gdzie każde drzewo jest trenowane na losowym podzbiorze danych.\n",
    "2. **Bootstrap**: Każde drzewo jest trenowane na losowym podzbiorze danych treningowych, wybranym z powtórzeniami (tzw. bootstrap sample). Zazwyczaj wielkość podzbioru jest równa wielkości oryginalnego zbioru danych.\n",
    "3. **Losowy wybór cech**: W każdym węźle drzewa decyzyjnego wybierana jest losowa podgrupa cech (atrybutów), spośród których wybierana jest najlepsza cecha do podziału. To zmniejsza korelację między drzewami i zwiększa różnorodność.\n",
    "4. **Agregacja wyników**:\n",
    "   - Dla **klasyfikacji**: Wyniki drzew są łączone przez głosowanie większościowe (ang. majority voting).\n",
    "   - Dla **regresji**: Wyniki drzew są uśredniane.\n",
    "\n",
    "### Formalny opis matematyczny\n",
    "\n",
    "Załóżmy, że mamy zbiór danych treningowych $ D = \\{(x_1, y_1), (x_2, y_2), \\dots, (x_N, y_N)\\} $, gdzie $ x_i $ to wektor cech, a $ y_i $ to etykieta (dla klasyfikacji) lub wartość ciągła (dla regresji).\n",
    "\n",
    "#### Krok 1: Tworzenie podzbiorów danych\n",
    "Dla każdego drzewa $ t = 1, 2, \\dots, T $:\n",
    "- Losujemy z powtórzeniami podzbiór danych $ D_t $ o rozmiarze $ N $ (bootstrap sample).\n",
    "- Losowy podzbiór cech (np. $ \\sqrt{p} $ lub $ p/3 $, gdzie $ p $ to liczba wszystkich cech) jest wybierany w każdym węźle drzewa do określenia najlepszego podziału.\n",
    "\n",
    "#### Krok 2: Budowa drzew\n",
    "Każde drzewo $ h_t(x) $ jest trenowane na zbiorze $ D_t $. Drzewo podejmuje decyzje na podstawie reguł podziału opartych na wybranych cechach. W przeciwieństwie do pojedynczego drzewa decyzyjnego, las losowy ogranicza overfitting dzięki różnorodności drzew.\n",
    "\n",
    "#### Krok 3: Agregacja predykcji\n",
    "- Dla **klasyfikacji**:\n",
    "  Predykcja lasu losowego to klasa, która otrzymała najwięcej głosów od drzew:\n",
    "  $$\n",
    "  \\hat{y}(x) = \\text{mode} \\{ h_1(x), h_2(x), \\dots, h_T(x) \\},\n",
    "  $$\n",
    "  gdzie $ \\text{mode} $ oznacza najczęściej występującą klasę.\n",
    "- Dla **regresji**:\n",
    "  Predykcja to średnia predykcji wszystkich drzew:\n",
    "  $$\n",
    "  \\hat{y}(x) = \\frac{1}{T} \\sum_{t=1}^T h_t(x).\n",
    "  $$\n",
    "\n",
    "#### Krok 4: Ważność cech (Feature Importance)\n",
    "Lasy losowe mogą oceniać ważność cech na podstawie tego, jak bardzo każda cecha przyczynia się do zmniejszenia nieczystości (np. entropii lub współczynnika Gini) w węzłach drzew. Ważność cechy $ j $ można zapisać jako:\n",
    "$$\n",
    "\\text{Importance}(j) = \\frac{1}{T} \\sum_{t=1}^T \\sum_{\\text{węzły } v \\text{ w drzewie } t} \\Delta i(v, j),\n",
    "$$\n",
    "gdzie $ \\Delta i(v, j) $ to zmniejszenie nieczystości w węźle $ v $ dzięki cesze $ j $.\n",
    "\n",
    "### Zalety lasów losowych\n",
    "- Odporność na overfitting dzięki agregacji wielu drzew.\n",
    "- Dobra wydajność w zadaniach z dużą liczbą cech i szumem.\n",
    "- Możliwość oceny ważności cech.\n",
    "- Prosta implementacja i równoległe trenowanie drzew.\n",
    "\n",
    "### Wady\n",
    "- Wysoka złożoność obliczeniowa przy dużej liczbie drzew i danych.\n",
    "- Mniejsza interpretowalność w porównaniu do pojedynczego drzewa decyzyjnego.\n",
    "- Może być mniej skuteczny w zadaniach wymagających modelowania złożonych zależności (np. w porównaniu do gradient boosting).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012146a",
   "metadata": {},
   "source": [
    "### Zadanie nr 2 (3 punkty)\n",
    "Zbuduj model lasów losowych w Pythonie, używając scikit-learn, i oceń jego dokładność na syntetycznym zbiorze danych klasyfikacji binarnej.\n",
    "\n",
    "1. Wygeneruj zbiór danych binarnej klasyfikacji (użyj `make_classification`).\n",
    "2. Podziel dane na zbiór treningowy i testowy.\n",
    "3. Zbuduj model lasów losowych z 50 drzewami.\n",
    "4. Oceń dokładność modelu na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11753689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91011b97",
   "metadata": {},
   "source": [
    "# 🧠 Algorytm Gradient Boosting dla Klasyfikacji (Binary)\n",
    "\n",
    "## 🔢 Dane wejściowe\n",
    "\n",
    "- Zbiór uczący: \\( (x_1, y_1), \\dots, (x_n, y_n) \\), gdzie \\( y_i \\in \\{0, 1\\} \\)\n",
    "- Liczba iteracji (drzew): \\( T \\)\n",
    "- Learning rate: \\( \\eta \\in (0, 1] \\)\n",
    "- Funkcja straty: log-loss\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Algorytm\n",
    "\n",
    "### 1. Inicjalizacja\n",
    "\n",
    "Oblicz początkową wartość predykcji jako logit średniego udziału klasy pozytywnej:\n",
    "\n",
    "\\[\n",
    "\\hat{y}_0 = \\log \\left( \\frac{p}{1 - p} \\right), \\quad \\text{gdzie } p = \\frac{1}{n} \\sum_{i=1}^n y_i\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Dla każdej iteracji \\( t = 1 \\dots T \\):\n",
    "\n",
    "#### a) Oblicz prawdopodobieństwa\n",
    "\n",
    "\\[\n",
    "p_i^{(t-1)} = \\frac{1}{1 + e^{-\\hat{y}_{t-1}(x_i)}}\n",
    "\\]\n",
    "\n",
    "#### b) Oblicz pseudoreszty (gradient log-loss)\n",
    "\n",
    "\\[\n",
    "r_i^{(t)} = y_i - p_i^{(t-1)}\n",
    "\\]\n",
    "\n",
    "#### c) Naucz drzewo regresyjne \\( h_t(x) \\), dopasowujące się do \\( (x_i, r_i^{(t)}) \\)\n",
    "\n",
    "#### d) Zaktualizuj predykcję\n",
    "\n",
    "\\[\n",
    "\\hat{y}_t(x) = \\hat{y}_{t-1}(x) + \\eta \\cdot h_t(x)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Końcowa predykcja\n",
    "\n",
    "#### a) Prawdopodobieństwo klasy 1:\n",
    "\n",
    "\\[\n",
    "P(y = 1 \\mid x) = \\frac{1}{1 + e^{-\\hat{y}_T(x)}}\n",
    "\\]\n",
    "\n",
    "#### b) Klasa końcowa:\n",
    "\n",
    "\\[\n",
    "\\text{klasa}(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{jeśli } P(y=1 \\mid x) \\geq 0{,}5 \\\\\n",
    "0 & \\text{w przeciwnym razie}\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Uwagi\n",
    "\n",
    "- Dla klasyfikacji wieloklasowej używa się softmax zamiast sigmoid.\n",
    "- W praktyce często stosuje się też drugą pochodną (Newton step).\n",
    "- Popularne implementacje: `XGBoost`, `LightGBM`, `CatBoost`, `sklearn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf773d",
   "metadata": {},
   "source": [
    "### Zadanie nr 3 (1 punkt)\n",
    "Zbuduj model Gradient Boosting w Pythonie na danych `make_moons` i oceń jego dokładność.\n",
    "\n",
    "### Instrukcje\n",
    "1. Wygeneruj zbiór danych `make_moons` (500 próbek, szum 0.2).\n",
    "2. Podziel dane na treningowe i testowe (30% testowe).\n",
    "3. Zbuduj model Gradient Boosting z 100 drzewami i learning rate 0.1.\n",
    "4. Wypisz dokładność na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e57bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a8188a",
   "metadata": {},
   "source": [
    "# Random Search\n",
    "\n",
    "Random Search (ang. losowe przeszukiwanie) to metoda strojenia hiperparametrów modelu uczenia maszynowego, polegająca na losowym próbkowaniu kombinacji wartości hiperparametrów z zadanego zakresu, zamiast testowania wszystkich możliwych kombinacji (jak w Grid Search). Dla każdej losowej kombinacji model jest trenowany i oceniany (np. za pomocą walidacji krzyżowej), a najlepsza kombinacja jest wybierana.\n",
    "\n",
    "### Kluczowe cechy:\n",
    "- **Losowość**: Hiperparametry są losowane z zdefiniowanych rozkładów (np. jednorodnego, logarytmicznego).\n",
    "- **Efektywność**: Testuje mniejszą liczbę kombinacji niż Grid Search, co przyspiesza proces dla dużych przestrzeni hiperparametrów.\n",
    "- **Elastyczność**: Pozwala na określenie zakresów ciągłych (np. learning rate od 0.001 do 0.1) lub dyskretnych (np. liczba drzew: 50, 100, 200).\n",
    "\n",
    "### Matematyka:\n",
    "Niech $ \\Theta $ to przestrzeń hiperparametrów (np. $\\Theta = \\{ \\text{n\\_estimators}, \\text{learning\\_rate}, \\text{max\\_depth} \\}$). Random Search losuje $ n $ kombinacji $ \\theta_1, \\theta_2, \\dots, \\theta_n \\in \\Theta $ z rozkładu (np. jednorodnego) i ocenia model dla każdej $ \\theta_i $ za pomocą funkcji straty $ L(\\theta_i) $ (np. średni błąd walidacji krzyżowej). Wybiera:\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta_i} L(\\theta_i).\n",
    "$$\n",
    "\n",
    "### Dlaczego Random Search jest ważny?\n",
    "- **Szybsze niż Grid Search**: W dużych przestrzeniach hiperparametrów testuje mniej kombinacji, zachowując wysoką szansę na znalezienie dobrych wartości.\n",
    "- **Skuteczność w wysokich wymiarach**: Losowe próbkowanie lepiej eksploruje przestrzeń niż systematyczne grid search, zwłaszcza gdy tylko niektóre hiperparametry mają duże znaczenie.\n",
    "- **Praktyczność**: Umożliwia strojenie modeli w rozsądnym czasie, co jest kluczowe w rzeczywistych zastosowaniach, gdzie zasoby obliczeniowe są ograniczone.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703249be",
   "metadata": {},
   "source": [
    "### Zadanie nr 4 (1 punkt)\n",
    "Użyj Random Search do strojenia hiperparametrów modelu XGBoost na danych `make_moons`, testując większą liczbę hiperparametrów, i wypisz najlepszą dokładność oraz wybrane hiperparametry.\n",
    "\n",
    "### Instrukcje\n",
    "1. Wygeneruj zbiór danych `make_moons` (500 próbek, szum 0.2).\n",
    "2. Podziel dane na treningowe i testowe (30% testowe).\n",
    "3. Użyj `RandomizedSearchCV`, aby znaleźć najlepsze hiperparametry dla XGBoost, testując: `n_estimators`, `learning_rate`, `max_depth`, `min_child_weight`, `subsample`.\n",
    "4. Wypisz najlepszą dokładność i najlepsze hiperparametry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24133f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
